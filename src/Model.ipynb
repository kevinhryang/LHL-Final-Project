{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Based Violence Classification\n",
    "\n",
    "Scratch work notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "train_df = pd.read_csv('../data/Train.csv')\n",
    "test_df = pd.read_csv('../data/Test.csv')\n",
    "extra_df = pd.read_csv('../data/ExtraTweets.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_df = extra_df.loc[extra_df['sentiment'] == 'neutral']\n",
    "neutral_df.rename(columns={'text':'tweet'}, inplace=True)\n",
    "neutral_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(text: string):\n",
    "    # Punctuation\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    #text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    # Numbers\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    text = text.split()\n",
    "    # Stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    # Join\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_df(df: pd.DataFrame):\n",
    "    df['preprocessed_tweet'] = df['tweet'].apply(lambda x: preprocess_string(x))\n",
    "    df['preprocessed_tweet'] = df['tweet'].apply(lambda x: preprocess_string(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess_df(train_df)\n",
    "test_df = preprocess_df(test_df)\n",
    "neutral_df = preprocess_df(neutral_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                  dream got rape last night guy work actual guy smoke hous much tryna sexual wasnt even like want smoke\n",
       "1                                                                                                          thought word rape mean sex told saw dog rape eachoth like wtf\n",
       "2                                                                                                                        talk rape men molest jail nother charg say word\n",
       "3                              sexual abus year age one believ rape bro friend classroom told one caus would believ bro found friend brag wrong person hard come forward\n",
       "4    chessi prout better tell truth sell owen labri hide whoever els dna underwear said never said rape chang chessi rape violat white femal privileg allow platform lie\n",
       "Name: preprocessed_tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['preprocessed_tweet'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=0.01)\n",
    "\n",
    "# Combine data in training and extra set to train TFIDF\n",
    "tfidf_train_data = pd.concat([train_df['preprocessed_tweet'], neutral_df['preprocessed_tweet']])\n",
    "\n",
    "# Fit TFIDF on data\n",
    "tfidf_trained = tfidf_vectorizer.fit(tfidf_train_data)\n",
    "\n",
    "# Transform columns\n",
    "tfidf_train = tfidf_trained.transform(train_df['preprocessed_tweet'])\n",
    "tfidf_test = tfidf_trained.transform(test_df['preprocessed_tweet'])\n",
    "tfidf_extra = tfidf_trained.transform(neutral_df['preprocessed_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11117"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_extra.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harmful_Traditional_practice',\n",
       " 'Physical_violence',\n",
       " 'economic_violence',\n",
       " 'emotional_violence',\n",
       " 'sexual_violence']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encode target\n",
    "le = LabelEncoder()\n",
    "train_df['encoded_type'] = le.fit_transform(train_df['type'])\n",
    "le.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final matrices for model usage\n",
    "X_train = vstack((tfidf_train, tfidf_extra)).toarray()\n",
    "#X_train = tfidf_train\n",
    "y_train = train_df['encoded_type'].to_list()\n",
    "y_train.extend(np.ones(tfidf_extra.shape[0])*5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'l1_ratio': 0.25, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Grid search to tune hyperparameters\n",
    "grid = {\n",
    "    \"C\": [0.25, 0.5, 0.75, 1],\n",
    "    \"penalty\": [\"l1\", \"l2\", 'elasticnet'],\n",
    "    'l1_ratio': [0.25, 0.5, 0.75]\n",
    "}\n",
    "grid_logreg = LogisticRegression(class_weight='balanced', multi_class='ovr', n_jobs=-1)\n",
    "logreg_cv = GridSearchCV(grid_logreg, grid, cv=5, scoring='f1_macro')\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "print(logreg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_logreg = LogisticRegression(\n",
    "    class_weight='balanced', \n",
    "    multi_class='ovr', \n",
    "    n_jobs=-1,\n",
    "    max_iter=1000,\n",
    "    C=1,\n",
    "    penalty='l2',\n",
    ")\n",
    "multi_logreg.fit(X_train, y_train)\n",
    "y_pred = multi_logreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "Harmful_Traditional_practice       0.53      0.91      0.67       188\n",
      "           Physical_violence       0.98      0.99      0.99      5946\n",
      "           economic_violence       0.69      1.00      0.82       217\n",
      "          emotional_violence       0.85      0.99      0.91       651\n",
      "             sexual_violence       1.00      0.98      0.99     32648\n",
      "                     neutral       0.97      0.99      0.98     11117\n",
      "\n",
      "                    accuracy                           0.98     50767\n",
      "                   macro avg       0.84      0.98      0.89     50767\n",
      "                weighted avg       0.99      0.98      0.98     50767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_train, y_pred, target_names=le.classes_.tolist()+['neutral']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[50427,   152],\n",
       "        [   17,   171]],\n",
       "\n",
       "       [[44713,   108],\n",
       "        [   35,  5911]],\n",
       "\n",
       "       [[50453,    97],\n",
       "        [    0,   217]],\n",
       "\n",
       "       [[50004,   112],\n",
       "        [    9,   642]],\n",
       "\n",
       "       [[18103,    16],\n",
       "        [  616, 32032]],\n",
       "\n",
       "       [[39313,   337],\n",
       "        [  145, 10972]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'got': 94,\n",
       " 'rape': 179,\n",
       " 'last': 124,\n",
       " 'night': 159,\n",
       " 'guy': 96,\n",
       " 'work': 262,\n",
       " 'actual': 2,\n",
       " 'hous': 109,\n",
       " 'much': 152,\n",
       " 'sexual': 197,\n",
       " 'wasnt': 247,\n",
       " 'even': 66,\n",
       " 'like': 131,\n",
       " 'want': 246,\n",
       " 'thought': 225,\n",
       " 'word': 261,\n",
       " 'mean': 146,\n",
       " 'sex': 196,\n",
       " 'told': 229,\n",
       " 'saw': 191,\n",
       " 'talk': 217,\n",
       " 'men': 147,\n",
       " 'jail': 117,\n",
       " 'say': 192,\n",
       " 'abus': 0,\n",
       " 'year': 269,\n",
       " 'age': 3,\n",
       " 'one': 164,\n",
       " 'believ': 23,\n",
       " 'friend': 84,\n",
       " 'caus': 37,\n",
       " 'would': 263,\n",
       " 'found': 83,\n",
       " 'wrong': 265,\n",
       " 'person': 168,\n",
       " 'hard': 99,\n",
       " 'come': 42,\n",
       " 'better': 25,\n",
       " 'tell': 218,\n",
       " 'said': 190,\n",
       " 'never': 156,\n",
       " 'chang': 38,\n",
       " 'white': 253,\n",
       " 'lie': 129,\n",
       " 'ye': 267,\n",
       " 'women': 259,\n",
       " 'also': 6,\n",
       " 'yet': 270,\n",
       " 'that': 220,\n",
       " 'man': 142,\n",
       " 'someth': 205,\n",
       " 'happen': 98,\n",
       " 'husband': 111,\n",
       " 'beat': 21,\n",
       " 'wife': 255,\n",
       " 'court': 46,\n",
       " 'sure': 215,\n",
       " 'yr': 273,\n",
       " 'old': 163,\n",
       " 'girl': 88,\n",
       " 'god': 91,\n",
       " 'find': 79,\n",
       " 'wont': 260,\n",
       " 'back': 18,\n",
       " 'time': 227,\n",
       " 'peopl': 167,\n",
       " 'ago': 4,\n",
       " 'tw': 235,\n",
       " 'sorri': 207,\n",
       " 'hear': 103,\n",
       " 'yeah': 268,\n",
       " 'threaten': 226,\n",
       " 'tri': 231,\n",
       " 'stop': 212,\n",
       " 'speak': 208,\n",
       " 'assault': 15,\n",
       " 'know': 123,\n",
       " 'understand': 239,\n",
       " 'father': 76,\n",
       " 'well': 251,\n",
       " 'mother': 151,\n",
       " 'kill': 121,\n",
       " 'right': 188,\n",
       " 'rememb': 185,\n",
       " 'made': 140,\n",
       " 'leav': 126,\n",
       " 'dont': 60,\n",
       " 'everi': 68,\n",
       " 'point': 172,\n",
       " 'think': 223,\n",
       " 'done': 59,\n",
       " 'anyth': 11,\n",
       " 'good': 93,\n",
       " 'enough': 65,\n",
       " 'job': 118,\n",
       " 'babi': 17,\n",
       " 'case': 36,\n",
       " 'yall': 266,\n",
       " 'victim': 242,\n",
       " 'take': 216,\n",
       " 'anoth': 9,\n",
       " 'give': 89,\n",
       " 'kid': 120,\n",
       " 'child': 39,\n",
       " 'day': 51,\n",
       " 'blame': 27,\n",
       " 'thing': 222,\n",
       " 'still': 211,\n",
       " 'im': 114,\n",
       " 'didnt': 54,\n",
       " 'read': 181,\n",
       " 'shit': 198,\n",
       " 'dude': 63,\n",
       " 'use': 241,\n",
       " 'stori': 213,\n",
       " 'he': 101,\n",
       " 'murder': 153,\n",
       " 'rapist': 180,\n",
       " 'amp': 8,\n",
       " 'support': 214,\n",
       " 'trump': 232,\n",
       " 'liter': 132,\n",
       " 'get': 87,\n",
       " 'around': 12,\n",
       " 'disgust': 57,\n",
       " 'pleas': 171,\n",
       " 'block': 28,\n",
       " 'lol': 135,\n",
       " 'walk': 245,\n",
       " 'tweet': 236,\n",
       " 'report': 187,\n",
       " 'way': 249,\n",
       " 'went': 252,\n",
       " 'dad': 48,\n",
       " 'sinc': 201,\n",
       " 'turn': 234,\n",
       " 'evid': 71,\n",
       " 'name': 154,\n",
       " 'care': 35,\n",
       " 'fact': 74,\n",
       " 'long': 136,\n",
       " 'home': 107,\n",
       " 'put': 178,\n",
       " 'mani': 143,\n",
       " 'make': 141,\n",
       " 'date': 49,\n",
       " 'follow': 81,\n",
       " 'call': 32,\n",
       " 'boyfriend': 30,\n",
       " 'hurt': 110,\n",
       " 'go': 90,\n",
       " 'fuck': 85,\n",
       " 'sick': 200,\n",
       " 'famili': 75,\n",
       " 'everyth': 70,\n",
       " 'black': 26,\n",
       " 'children': 40,\n",
       " 'ive': 116,\n",
       " 'us': 240,\n",
       " 'though': 224,\n",
       " 'isnt': 115,\n",
       " 'deserv': 53,\n",
       " 'life': 130,\n",
       " 'ass': 14,\n",
       " 'best': 24,\n",
       " 'today': 228,\n",
       " 'id': 112,\n",
       " 'hed': 104,\n",
       " 'polic': 173,\n",
       " 'cop': 43,\n",
       " 'young': 271,\n",
       " 'oh': 161,\n",
       " 'could': 44,\n",
       " 'week': 250,\n",
       " 'ever': 67,\n",
       " 'away': 16,\n",
       " 'left': 127,\n",
       " 'month': 150,\n",
       " 'sleep': 203,\n",
       " 'video': 243,\n",
       " 'see': 195,\n",
       " 'let': 128,\n",
       " 'came': 33,\n",
       " 'place': 169,\n",
       " 'woman': 258,\n",
       " 'watch': 248,\n",
       " 'wait': 244,\n",
       " 'daughter': 50,\n",
       " 'your': 272,\n",
       " 'drunk': 62,\n",
       " 'cri': 47,\n",
       " 'ex': 72,\n",
       " 'lot': 138,\n",
       " 'hope': 108,\n",
       " 'help': 106,\n",
       " 'proof': 176,\n",
       " 'accus': 1,\n",
       " 'wish': 256,\n",
       " 'anyon': 10,\n",
       " 'ask': 13,\n",
       " 'bc': 20,\n",
       " 'mayb': 145,\n",
       " 'reason': 184,\n",
       " 'look': 137,\n",
       " 'gonna': 92,\n",
       " 'keep': 119,\n",
       " 'show': 199,\n",
       " 'feel': 77,\n",
       " 'next': 158,\n",
       " 'start': 209,\n",
       " 'knew': 122,\n",
       " 'two': 238,\n",
       " 'public': 177,\n",
       " 'mom': 148,\n",
       " 'took': 230,\n",
       " 'school': 194,\n",
       " 'gave': 86,\n",
       " 'felt': 78,\n",
       " 'without': 257,\n",
       " 'play': 170,\n",
       " 'noth': 160,\n",
       " 'forc': 82,\n",
       " 'ok': 162,\n",
       " 'almost': 5,\n",
       " 'drug': 61,\n",
       " 'couldnt': 45,\n",
       " 'littl': 133,\n",
       " 'cant': 34,\n",
       " 'bad': 19,\n",
       " 'marri': 144,\n",
       " 'post': 174,\n",
       " 'realli': 183,\n",
       " 'face': 73,\n",
       " 'wouldnt': 264,\n",
       " 'need': 155,\n",
       " 'alway': 7,\n",
       " 'hate': 100,\n",
       " 'everyon': 69,\n",
       " 'someon': 204,\n",
       " 'claim': 41,\n",
       " 'live': 134,\n",
       " 'die': 55,\n",
       " 'first': 80,\n",
       " 'brother': 31,\n",
       " 'love': 139,\n",
       " 'new': 157,\n",
       " 'real': 182,\n",
       " 'part': 166,\n",
       " 'parent': 165,\n",
       " 'death': 52,\n",
       " 'prison': 175,\n",
       " 'there': 221,\n",
       " 'money': 149,\n",
       " 'twitter': 237,\n",
       " 'doesnt': 58,\n",
       " 'hell': 105,\n",
       " 'later': 125,\n",
       " 'end': 64,\n",
       " 'whole': 254,\n",
       " 'head': 102,\n",
       " 'boy': 29,\n",
       " 'son': 206,\n",
       " 'ill': 113,\n",
       " 'differ': 56,\n",
       " 'trust': 233,\n",
       " 'scare': 193,\n",
       " 'thank': 219,\n",
       " 'room': 189,\n",
       " 'bed': 22,\n",
       " 'guess': 95,\n",
       " 'stay': 210,\n",
       " 'sister': 202,\n",
       " 'remind': 186,\n",
       " 'hand': 97}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 90, 262, 157, 228, 135])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_logreg.coef_[5].argsort()[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turn'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(tfidf_vectorizer.vocabulary_)\n",
    "vocab[135]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
